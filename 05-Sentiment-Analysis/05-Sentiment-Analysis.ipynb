{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN/kPQ6+2icOTORSpmqpexX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/myomyint-maung/nlp-assignments/blob/main/05-Sentiment-Analysis/05-Sentiment-Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import torch, torchdata, torchtext\n",
        "from torch import nn\n",
        "import time"
      ],
      "metadata": {
        "id": "MOFVNFmpF6N1"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose computing device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iCENv7LmGvmM",
        "outputId": "82f5ee15-bdb6-4fa3-da48-b189e88e74fe"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set SEED for reproducibility\n",
        "SEED = 786\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "metadata": {
        "id": "aVpZ0-BAHUOh"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. ETL"
      ],
      "metadata": {
        "id": "Nl2U86yqLgNf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load AG_NEWS dataset from torchtext\n",
        "from torchtext.datasets import  AG_NEWS\n",
        "train_set, test_set = AG_NEWS()"
      ],
      "metadata": {
        "id": "mkkAtJyKK_BK"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. EDA"
      ],
      "metadata": {
        "id": "KladKjbdNEuj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check a sample from the training dataset\n",
        "next(iter(train_set))"
      ],
      "metadata": {
        "id": "eCYKmm1KcHnP",
        "outputId": "00ade3b0-1c9a-41f0-99af-5a9404b88111",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3,\n",
              " \"Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling\\\\band of ultra-cynics, are seeing green again.\")"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the classes of labels in the trianing dataset\n",
        "set([y for y, x in list(iter(train_set))])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60WgAubFMBT7",
        "outputId": "5a0fb70d-88d3-4f42-c591-0ceec634af33"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{1, 2, 3, 4}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the size of the datasets\n",
        "train_size = len(list(iter(train_set)))\n",
        "test_size = len(list(iter(test_set)))\n",
        "\n",
        "train_size, test_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UnwZ8cYjN7va",
        "outputId": "c87c4d1e-8a9d-446b-fa52-e170459f39b4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(120000, 7600)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the training dataset into training and validation data\n",
        "train_data, val_data = train_set.random_split(total_length = train_size,\n",
        "                                  weights = {\"train_data\": 0.8,\n",
        "                                             \"val_data\": 0.2},\n",
        "                                  seed = SEED)"
      ],
      "metadata": {
        "id": "V36lOE_VOS97"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the sizes of the training and validation data\n",
        "train_size = len(list(iter(train_data)))\n",
        "val_size = len(list(iter(val_data)))\n",
        "\n",
        "train_size, val_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0y0Q0w7hPnhg",
        "outputId": "ca0728b1-ff9b-42f1-e97a-176b881e1ddf"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(96000, 24000)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Preprocessing"
      ],
      "metadata": {
        "id": "gU2pG4DJQ-Nj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3.1. Tokenization"
      ],
      "metadata": {
        "id": "8eyU-wyPRRMG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import get_tokenizer module and create tokenizer\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "\n",
        "tokenizer = get_tokenizer('spacy', language='en_core_web_sm')"
      ],
      "metadata": {
        "id": "iT3PUyx3Qyy5"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a function to get tokens out of datapipe objects\n",
        "def yield_tokens(data_iter):\n",
        "  for _, text in data_iter:\n",
        "    yield tokenizer(text)"
      ],
      "metadata": {
        "id": "75zJ6_KATiAq"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3.2. Numericalization"
      ],
      "metadata": {
        "id": "sudE8LGmS-4S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import vocab builder module\n",
        "from torchtext.vocab import build_vocab_from_iterator"
      ],
      "metadata": {
        "id": "AZMSUZBPRuX2"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create vocab out of the training set\n",
        "vocab = build_vocab_from_iterator(yield_tokens(train_data), specials=['<unk>',\n",
        "                                                                 '<pad>',\n",
        "                                                                 '<bos>',\n",
        "                                                                 '<eos>'])"
      ],
      "metadata": {
        "id": "r1gV8jvYTxwh"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set <unk> as the default index of the vocab\n",
        "vocab.set_default_index(vocab['<unk>'])"
      ],
      "metadata": {
        "id": "vcFX9uTQUQcU"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make idex2word dictionary\n",
        "index2word = vocab.get_itos()"
      ],
      "metadata": {
        "id": "VqwG37kEU7mq"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab(['<unk>', '<pad>', '<bos>', '<eos>'])"
      ],
      "metadata": {
        "id": "o6Kndl6ZVlkJ",
        "outputId": "95e1cab9-0bd8-4268-ff3e-80667080f625",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 2, 3]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index2word[0:4]"
      ],
      "metadata": {
        "id": "cDrkLC8yW70-",
        "outputId": "94dd5553-bf3d-40c5-eca7-db94c8365f16",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<unk>', '<pad>', '<bos>', '<eos>']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(vocab), len(index2word)"
      ],
      "metadata": {
        "id": "KF7k_l_kXIOB",
        "outputId": "b201aa96-b7b7-4cff-aa7a-70111b181174",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100157, 100157)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mu_v4XMdYVKR"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. FastText Embedding"
      ],
      "metadata": {
        "id": "k7fP_vs2Ybju"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import FastText module\n",
        "from torchtext.vocab import FastText"
      ],
      "metadata": {
        "id": "RtvYbtc2YX26"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load FastText embeddings\n",
        "fast_vectors = FastText(language='simple')"
      ],
      "metadata": {
        "id": "BC_0cVtHY50i"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select FastText embeddings for the vocab\n",
        "fast_embeddings = fast_vectors.get_vecs_by_tokens(index2word).to(device)"
      ],
      "metadata": {
        "id": "ZZs--mSiZmOi"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fast_embeddings.shape"
      ],
      "metadata": {
        "id": "cM8-DUCVaykt",
        "outputId": "154442f3-9dbd-4e41-95ee-43aff9b5d8dc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([100157, 300])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index2word[100]"
      ],
      "metadata": {
        "id": "hR1EMxxva13z",
        "outputId": "aaeb5ed9-676b-4777-e0a5-fa8224e906e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'could'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fast_embeddings[100]"
      ],
      "metadata": {
        "id": "yZksOrEZa75z",
        "outputId": "6a47b2eb-4baf-4cef-914d-36d1c597d2b8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.0037,  0.1285,  0.0932, -0.2673,  0.1011,  0.1499,  0.1140,  0.1750,\n",
              "        -0.0178,  0.4580, -0.0826,  0.0063, -0.0187, -0.2067,  0.0396, -0.2027,\n",
              "         0.0928,  0.1267, -0.1514, -0.2401,  0.0364,  0.4860, -0.1342, -0.1955,\n",
              "         0.1271,  0.0131,  0.0889, -0.1578,  0.1628,  0.0940,  0.0730,  0.0811,\n",
              "         0.2384,  0.2504,  0.1369,  0.0018,  0.0270, -0.2334,  0.0319, -0.0582,\n",
              "         0.0489, -0.0808,  0.4670, -0.1315, -0.0889,  0.0124, -0.1562, -0.1325,\n",
              "         0.1588,  0.2278,  0.0296, -0.1468, -0.0101,  0.1050,  0.1034, -0.1700,\n",
              "        -0.0410,  0.2820,  0.0088,  0.2146,  0.0196, -0.0028,  0.0834, -0.2325,\n",
              "        -0.1137, -0.2882, -0.2333, -0.0011,  0.2132, -0.1755,  0.0518,  0.2206,\n",
              "         0.0532,  0.2875,  0.0120, -0.1471, -0.0881,  0.1321,  0.0479,  0.0872,\n",
              "        -0.0632,  0.0183, -0.2970, -0.1001,  0.1149, -0.2211, -0.1006,  0.1413,\n",
              "         0.1636, -0.1715,  0.1063,  0.0223,  0.1345,  0.0137, -0.1597,  0.2564,\n",
              "        -0.2729,  0.2309,  0.0853,  0.2312,  0.1162, -0.4974, -0.2653,  0.1722,\n",
              "        -0.1311,  0.3020,  0.0956, -0.1747, -0.2115, -0.0991, -0.2530, -0.2012,\n",
              "        -0.3612, -0.0949,  0.0765, -0.0462, -0.1214,  0.2122, -0.1266, -0.1694,\n",
              "         0.1054, -0.0050,  0.2262,  0.1515, -0.2530, -0.2326, -0.0405,  0.0697,\n",
              "         0.0159, -0.0068, -0.2328, -0.1319, -0.1117,  0.0730, -0.2419,  0.2426,\n",
              "        -0.1751,  0.1670, -0.2487,  0.1116,  0.0097,  0.1666,  0.4562,  0.0159,\n",
              "         0.3227,  0.1194, -0.0927,  0.0992, -0.1502,  0.0464, -0.0084, -0.1630,\n",
              "        -0.0110, -0.1629,  0.2704,  0.0193, -0.0338,  0.3140,  0.0499,  0.2514,\n",
              "         0.1317,  0.1737, -0.0921, -0.0204,  0.2112, -0.1200,  0.0576, -0.0761,\n",
              "        -0.0986,  0.1740, -0.1455, -0.1097, -0.1814, -0.0071, -0.4673, -0.0974,\n",
              "        -0.0566, -0.1731,  0.1891, -0.1527, -0.1122, -0.2342,  0.0593,  0.0810,\n",
              "         0.1778, -0.1119,  0.1994,  0.2218,  0.0146,  0.4225, -0.0616,  0.2827,\n",
              "         0.3044,  0.1239,  0.1982,  0.2205, -0.5246,  0.0578,  0.0138, -0.1048,\n",
              "         0.3042,  0.2562, -0.1746,  0.0821,  0.0675, -0.1575, -0.0843, -0.2347,\n",
              "         0.0123, -0.1983,  0.0466,  0.2411,  0.3710, -0.2177, -0.0756,  0.2912,\n",
              "        -0.0143, -0.0114,  0.3902,  0.0822, -0.2803,  0.1416,  0.0054, -0.1528,\n",
              "        -0.0977, -0.1323, -0.1641,  0.0781, -0.1580,  0.0231,  0.1362,  0.3323,\n",
              "        -0.1076, -0.1806, -0.1249, -0.0338, -0.0417, -0.1780,  0.0055,  0.0569,\n",
              "         0.1179, -0.0259, -0.1462, -0.1260,  0.0792, -0.2016, -0.0400, -0.1156,\n",
              "        -0.1920,  0.1764, -0.2892,  0.2865, -0.1999, -0.3623,  0.0212, -0.1757,\n",
              "        -0.1478,  0.3720, -0.0466,  0.4451,  0.2969, -0.1416, -0.0870,  0.3363,\n",
              "         0.0853,  0.1094,  0.2086, -0.0353, -0.0421, -0.1512, -0.1829,  0.0167,\n",
              "         0.1307, -0.1346,  0.0306,  0.2284,  0.0204, -0.2041,  0.0147,  0.0392,\n",
              "         0.0878, -0.0482, -0.2941, -0.0104, -0.1147,  0.2299, -0.1938, -0.0112,\n",
              "         0.0070, -0.0175,  0.1254,  0.2118,  0.1269, -0.1336, -0.1331, -0.0820,\n",
              "        -0.0697,  0.1713, -0.2454, -0.3135], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Preparing Dataloader"
      ],
      "metadata": {
        "id": "sqYWWAIXcn0t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import DataLoader and pad_sequence from PyTorch\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence"
      ],
      "metadata": {
        "id": "oJLhfGVQa-md"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a function to collate batches of data\n",
        "def collate_batch(batch):\n",
        "  label_list, text_list, length_list = [], [], []\n",
        "\n",
        "  label_pipeline = lambda x: int(x) - 1\n",
        "  text_pipeline = lambda x: vocab(tokenizer(x))\n",
        "\n",
        "  for (_label, _text) in batch:\n",
        "    label_list.append(label_pipeline(_label))\n",
        "    processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n",
        "    text_list.append(processed_text)\n",
        "    length_list.append(processed_text.size(0))\n",
        "  \n",
        "  return torch.tensor(label_list, dtype=torch.int64), \\\n",
        "         pad_sequence(text_list, padding_value=vocab['<pad>'], batch_first=True), \\\n",
        "         torch.tensor(length_list, dtype=torch.int64)"
      ],
      "metadata": {
        "id": "Q0gx3OdYd67E"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size,\n",
        "                          shuffle=True, collate_fn=collate_batch)\n",
        "\n",
        "val_loader = DataLoader(val_data, batch_size=batch_size,\n",
        "                        shuffle=True, collate_fn=collate_batch)\n",
        "\n",
        "test_loader = DataLoader(test_set, batch_size=batch_size,\n",
        "                        shuffle=True, collate_fn=collate_batch)"
      ],
      "metadata": {
        "id": "WHBhhzK0hVRl"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for label, text, length in train_loader:\n",
        "  break\n",
        "\n",
        "label, text, length"
      ],
      "metadata": {
        "id": "fHKsUqnWlQRf",
        "outputId": "34064495-4f61-4b61-d3d1-5f5379e764b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([2, 2, 0, 2, 0, 2, 0, 3, 2, 2, 2, 0, 3, 3, 2, 1, 0, 2, 0, 1, 1, 0, 2, 2,\n",
              "         0, 1, 2, 1, 0, 3, 0, 2, 3, 0, 3, 3, 1, 0, 1, 0, 2, 3, 3, 0, 3, 1, 3, 2,\n",
              "         3, 1, 1, 1, 3, 1, 3, 2, 3, 1, 2, 3, 2, 1, 1, 0]),\n",
              " tensor([[  973,   605,    32,  ...,     1,     1,     1],\n",
              "         [12029,  5046, 12726,  ...,     1,     1,     1],\n",
              "         [19742,    77,  7856,  ...,     1,     1,     1],\n",
              "         ...,\n",
              "         [73383, 15790,    16,  ...,     1,     1,     1],\n",
              "         [  240,     5,    67,  ...,     1,     1,     1],\n",
              "         [ 1779,     7,  7799,  ...,     1,     1,     1]]),\n",
              " tensor([46, 49, 25, 44, 53, 48, 82, 57, 40, 46, 45, 50, 21, 48, 44, 56, 46, 52,\n",
              "         38, 37, 49, 29, 67, 50, 42, 42, 45, 45, 45, 45, 49, 35, 36, 40, 28, 34,\n",
              "         77, 42, 45, 42, 51, 34, 91, 50, 43, 37, 49, 31, 29, 38, 46, 38, 87, 59,\n",
              "         57, 38, 42, 48, 61, 18, 57, 42, 34, 56]))"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label.shape, text.shape, length.shape"
      ],
      "metadata": {
        "id": "UYf-NpizljGz",
        "outputId": "9016aeed-fccc-4c8a-d7b3-f72e8d7c342a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([64]), torch.Size([64, 91]), torch.Size([64]))"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Designing the Model"
      ],
      "metadata": {
        "id": "1UpDB8mJnfmN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the LSTM model\n",
        "class LSTM(nn.Module):\n",
        "\n",
        "  def __init__(self, input_dim, emb_dim, hid_dim, output_dim, num_layers, bidirectional, dropout):\n",
        "    super().__init__()\n",
        "\n",
        "    self.embedding = nn.Embedding(input_dim, emb_dim, padding_idx=vocab['<pad>'])\n",
        "    \n",
        "    self.lstm = nn.LSTM(emb_dim, hid_dim,\n",
        "                        num_layers = num_layers,\n",
        "                        bidirectional = bidirectional,\n",
        "                        dropout = dropout,\n",
        "                        batch_first = True)\n",
        "    \n",
        "    self.fc = nn.Linear(hid_dim * 2, output_dim)\n",
        "  \n",
        "  def forward(self, x, lengths):\n",
        "\n",
        "    embedded_x = self.embedding(x)\n",
        "\n",
        "    pack_embedded = nn.utils.rnn.pack_padded_sequence(embedded_x,\n",
        "                                                      lengths.to('cpu'),\n",
        "                                                      enforce_sorted=False,\n",
        "                                                      batch_first=True)\n",
        "    \n",
        "    packed_output, (h, c) = self.lstm(pack_embedded)\n",
        "\n",
        "    output, output_length = nn.utils.rnn.pad_packed_sequence(packed_output, batch_first=True)\n",
        "\n",
        "    last_hidden_state = torch.cat((h[-1,:,:], h[-2,:,:]), dim=1)\n",
        "\n",
        "    return self.fc(last_hidden_state)"
      ],
      "metadata": {
        "id": "ukYLTp61mz7K"
      },
      "execution_count": 30,
      "outputs": []
    }
  ]
}