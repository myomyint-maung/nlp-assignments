{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape Twitter tweets with snscrape\n",
    "import snscrape.modules.twitter as sntwitter\n",
    "\n",
    "query = \"#bitcoin\"\n",
    "tweets = []\n",
    "limit = 100\n",
    "\n",
    "for tweet in sntwitter.TwitterSearchScraper(query).get_items():\n",
    "\n",
    "    if len(tweets) == limit:\n",
    "        break\n",
    "    else:\n",
    "        if tweet.lang=='en':\n",
    "            tweets.append(str(tweet.rawContent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Tweet   100 non-null    object\n",
      "dtypes: object(1)\n",
      "memory usage: 928.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "# Store the tweets in a dataframe\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(tweets, columns=['Tweet'])\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ü•≥ FBBank Giveaway ÔºÅüí∞\\n\\nüèÜ Prize Pool : $200 wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Join Mega Airdrop by @Coinstages x @TokenBrics...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Orangepill fail today by me. \\n\\nI got a colle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>- \\nBTC price: $24,672 / ¬£20,616 \\n\\n40.53 Nak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>San Francisco federal bank eyes CBDC system de...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet\n",
       "0  ü•≥ FBBank Giveaway ÔºÅüí∞\\n\\nüèÜ Prize Pool : $200 wo...\n",
       "1  Join Mega Airdrop by @Coinstages x @TokenBrics...\n",
       "2  Orangepill fail today by me. \\n\\nI got a colle...\n",
       "3  - \\nBTC price: $24,672 / ¬£20,616 \\n\\n40.53 Nak...\n",
       "4  San Francisco federal bank eyes CBDC system de..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the model environment\n",
    "import torch, torchtext, torchdata\n",
    "from torch import nn\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "SEED = 1234\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "from torchtext.datasets import SST2\n",
    "train = SST2(split='train')\n",
    "\n",
    "tokenizer = get_tokenizer('spacy', language='en_core_web_sm')\n",
    "\n",
    "def yield_tokens(data_iter):\n",
    "    for text, _ in data_iter:\n",
    "        yield tokenizer(text)\n",
    "        \n",
    "vocab = build_vocab_from_iterator(yield_tokens(train),\n",
    "                                  specials=['<unk>','<pad>','<bos>','<eos>'])\n",
    "\n",
    "vocab.set_default_index(vocab['<unk>'])\n",
    "\n",
    "text_pipeline  = lambda x: vocab(tokenizer(x))\n",
    "label_pipeline = lambda x: int(x) - 1\n",
    "\n",
    "pad_idx = vocab['<pad>']\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, hid_dim, output_dim, num_layers, bidirectional, dropout):\n",
    "        super().__init__()\n",
    "        #put padding_idx so asking the embedding layer to ignore padding\n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim, padding_idx=pad_idx)\n",
    "        self.lstm = nn.LSTM(emb_dim, \n",
    "                           hid_dim, \n",
    "                           num_layers=num_layers, \n",
    "                           bidirectional=bidirectional, \n",
    "                           dropout=dropout,\n",
    "                           batch_first=True)\n",
    "        self.fc = nn.Linear(hid_dim * 2, output_dim)\n",
    "        \n",
    "    def forward(self, text, text_lengths):\n",
    "        #text = [batch size, seq len]\n",
    "        embedded = self.embedding(text)\n",
    "        \n",
    "        #++ pack sequence ++\n",
    "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths.to('cpu'), enforce_sorted=False, batch_first=True)\n",
    "        \n",
    "        #embedded = [batch size, seq len, embed dim]\n",
    "        packed_output, (hn, cn) = self.lstm(packed_embedded)  #if no h0, all zeroes\n",
    "        \n",
    "        #++ unpack in case we need to use it ++\n",
    "        output, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output, batch_first=True)\n",
    "        \n",
    "        #output = [batch size, seq len, hidden dim * num directions]\n",
    "        #output over padding tokens are zero tensors\n",
    "        \n",
    "        #hidden = [num layers * num directions, batch size, hid dim]\n",
    "        #cell = [num layers * num directions, batch size, hid dim]\n",
    "        \n",
    "        #concat the final forward (hidden[-2,:,:]) and backward (hidden[-1,:,:]) hidden layers\n",
    "        hn = torch.cat((hn[-2,:,:], hn[-1,:,:]), dim = 1)\n",
    "        #hn = [batch size, hidden dim * num directions]\n",
    "        \n",
    "        return self.fc(hn)\n",
    "\n",
    "input_dim  = len(vocab)\n",
    "hid_dim    = 256\n",
    "emb_dim    = 300\n",
    "output_dim = 2\n",
    "num_layers = 2\n",
    "bidirectional = True\n",
    "dropout = 0.5\n",
    "\n",
    "model = LSTM(input_dim, emb_dim, hid_dim, output_dim, num_layers, bidirectional, dropout).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the pretrained LSTM model\n",
    "save_path = f'models/{model.__class__.__name__}_SST2.pt'\n",
    "\n",
    "model.load_state_dict(torch.load(save_path, map_location=torch.device(device)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify the sentiments of the tweets\n",
    "def predict(text, text_length):\n",
    "    with torch.no_grad():\n",
    "        output = model(text, text_length).squeeze(1)\n",
    "        predicted = torch.max(output.data, 1)[1]\n",
    "        return predicted\n",
    "\n",
    "sentiment = []\n",
    "\n",
    "for tweet in tweets:\n",
    "    tweet = torch.tensor(text_pipeline(tweet))\n",
    "    tweet = tweet.reshape(1, -1)\n",
    "    tweet_length = torch.tensor([tweet.size(1)]).to(dtype=torch.int64)\n",
    "    prediction = str(int(predict(tweet, tweet_length))).strip()\n",
    "    sentiment.append(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the sentiments in the dataframe\n",
    "df['Sentiment'] = sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ü•≥ FBBank Giveaway ÔºÅüí∞\\n\\nüèÜ Prize Pool : $200 wo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Join Mega Airdrop by @Coinstages x @TokenBrics...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Orangepill fail today by me. \\n\\nI got a colle...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>- \\nBTC price: $24,672 / ¬£20,616 \\n\\n40.53 Nak...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>San Francisco federal bank eyes CBDC system de...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet Sentiment\n",
       "0  ü•≥ FBBank Giveaway ÔºÅüí∞\\n\\nüèÜ Prize Pool : $200 wo...         0\n",
       "1  Join Mega Airdrop by @Coinstages x @TokenBrics...         0\n",
       "2  Orangepill fail today by me. \\n\\nI got a colle...         0\n",
       "3  - \\nBTC price: $24,672 / ¬£20,616 \\n\\n40.53 Nak...         0\n",
       "4  San Francisco federal bank eyes CBDC system de...         0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method IndexOpsMixin.value_counts of 0     0\n",
       "1     0\n",
       "2     0\n",
       "3     0\n",
       "4     0\n",
       "     ..\n",
       "95    0\n",
       "96    0\n",
       "97    0\n",
       "98    0\n",
       "99    0\n",
       "Name: Sentiment, Length: 100, dtype: object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Sentiment.value_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "My_Virtual_Environment",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f7ca07084f99cae884d00a2401f5a915152405bd446c47609c53897335e04337"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
