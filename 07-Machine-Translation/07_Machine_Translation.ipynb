{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/myomyint-maung/nlp-assignments/blob/main/07-Machine-Translation/07_Machine_Translation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eus6ws8gS-oW"
      },
      "source": [
        "# 23 Feb - Machine Translation from Myanmar to English"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UuPqwROuS-oY",
        "outputId": "ae376b93-9281-47a2-8c62-02b72f3e8e69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import torch, torchtext\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import random, math, time\n",
        "\n",
        "# Choose the computing device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "\n",
        "# Set SEED for reproducibility\n",
        "SEED = 1234\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6vCQ7_FS-oa",
        "jp-MarkdownHeadingCollapsed": true,
        "tags": []
      },
      "source": [
        "## 1. Loading Data\n",
        "\n",
        "**Note**: I use the Myanmar and English datasets from the Asian Language Treebank (ALT) Parallel Corpus available at https://www2.nict.go.jp/astrec-att/member/mutiyama/ALT/."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!git clone https://github.com/myomyint-maung/nlp-assignments.git\n",
        "\n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "nEX-iwdtTFQb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "8p7OI83oS-oa",
        "outputId": "26bf6c73-33c1-47a6-9790-91c522d3dab4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 19166 entries, 0 to 19172\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   MY      19166 non-null  object\n",
            " 1   EN      19166 non-null  object\n",
            "dtypes: object(2)\n",
            "memory usage: 449.2+ KB\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  MY  \\\n",
              "0  ပြင်သစ်နိုင်ငံ ပါရီမြို့ ပါ့ဒက်စ် ပရင့်စက် ၌ ၂...   \n",
              "1  အန်ဒရီယာ မာစီ သည် အီတလီ အတွက် စမ်းသပ်မှု တစ်ခု...   \n",
              "2  ပထမ တစ်ဝက် ၏ တော်တော်များများ အတွက် ကစားပွဲ ကိ...   \n",
              "3  ပေါ်တူဂီ သည် ဘယ်သောအခါမှ စွန့်လွှတ်မှု မရှိခဲ့...   \n",
              "4  အီတလီ သည် ပထမပိုင်း ၌ ၁၆-၅ ဖြင့် ဦးဆောင်ခဲ့ သေ...   \n",
              "\n",
              "                                                  EN  \n",
              "0  Italy have defeated Portugal 31-5 in Pool C of...  \n",
              "1  Andrea Masi opened the scoring in the fourth m...  \n",
              "2  Despite controlling the game for much of the f...  \n",
              "3  Portugal never gave up and David Penalva score...  \n",
              "4  Italy led 16-5 at half time but were matched b...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-309e8638-fe5e-4354-ad68-c6d46f56da2c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MY</th>\n",
              "      <th>EN</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ပြင်သစ်နိုင်ငံ ပါရီမြို့ ပါ့ဒက်စ် ပရင့်စက် ၌ ၂...</td>\n",
              "      <td>Italy have defeated Portugal 31-5 in Pool C of...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>အန်ဒရီယာ မာစီ သည် အီတလီ အတွက် စမ်းသပ်မှု တစ်ခု...</td>\n",
              "      <td>Andrea Masi opened the scoring in the fourth m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ပထမ တစ်ဝက် ၏ တော်တော်များများ အတွက် ကစားပွဲ ကိ...</td>\n",
              "      <td>Despite controlling the game for much of the f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ပေါ်တူဂီ သည် ဘယ်သောအခါမှ စွန့်လွှတ်မှု မရှိခဲ့...</td>\n",
              "      <td>Portugal never gave up and David Penalva score...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>အီတလီ သည် ပထမပိုင်း ၌ ၁၆-၅ ဖြင့် ဦးဆောင်ခဲ့ သေ...</td>\n",
              "      <td>Italy led 16-5 at half time but were matched b...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-309e8638-fe5e-4354-ad68-c6d46f56da2c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-309e8638-fe5e-4354-ad68-c6d46f56da2c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-309e8638-fe5e-4354-ad68-c6d46f56da2c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "# Load the datasets\n",
        "import pandas as pd\n",
        "\n",
        "data_my = pd.read_csv('/content/nlp-assignments/07-Machine-Translation/data/data_my.txt', sep='\\t', header=None)\n",
        "data_en = pd.read_csv('/content/nlp-assignments/07-Machine-Translation/data/data_en.txt', sep='\\t', header=None)\n",
        "\n",
        "data_my.columns = ['REF', 'MY']\n",
        "data_en.columns = ['REF', 'EN']\n",
        "\n",
        "df = pd.merge(data_my, data_en, on='REF')\n",
        "df = df.drop('REF', axis=1)\n",
        "df = df.dropna()\n",
        "\n",
        "df.info()\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "crIVyZSmfSpu",
        "outputId": "621020b4-e6f9-439b-be73-786a3591edf9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['ပြင်သစ်နိုင်ငံ ပါရီမြို့ ပါ့ဒက်စ် ပရင့်စက် ၌ ၂၀၀၇ခုနှစ် ရပ်ဘီ ကမ္ဘာ့ ဖလား တွင် အီတလီ သည် ပေါ်တူဂီ ကို ၃၁-၅ ဂိုး ဖြင့် ရေကူးကန် စီ တွင် ရှုံးနိမ့်သွားပါသည် ။',\n",
              "  'Italy have defeated Portugal 31-5 in Pool C of the 2007 Rugby World Cup at Parc des Princes, Paris, France.'],\n",
              " ['အန်ဒရီယာ မာစီ သည် အီတလီ အတွက် စမ်းသပ်မှု တစ်ခု အဖြစ် စတုတ္ထ မိနစ် တွင် အမှတ်ပေးခြင်း ကို ဖွင့်လှစ်ပေးခဲ့သည် ။',\n",
              "  'Andrea Masi opened the scoring in the fourth minute with a try for Italy.'],\n",
              " ['ပထမ တစ်ဝက် ၏ တော်တော်များများ အတွက် ကစားပွဲ ကို ထိန်းချုပ်ခြင်း မရှိခဲ့လျှင် အီတလီ သည် ပွဲနားချိန် မတိုင်မှီ အခြား မည်သည့် ကြိုးစားမှု များ ကိုမှ အမှတ် မရနိုင် ပေမယ့် ဒေးဗစ် ဘော်တိုလပ်စီ သည် သူတို့၏ ဦးဆောင်မှု ကို အဓွန့်ရှည် စေရန် ပယ်နယ်လ်တီ ၃ဂိုး သွင်းပေးခဲ့သည် ။',\n",
              "  'Despite controlling the game for much of the first half, Italy could not score any other tries before the interval but David Bortolussi kicked three penalties to extend their lead.'],\n",
              " ['ပေါ်တူဂီ သည် ဘယ်သောအခါမှ စွန့်လွှတ်မှု မရှိခဲ့ ပဲ ဒေးဗစ် ပန်နယ်ဗါ သည် ၃၃ မိနစ် တွင် သူတို့ ၏ ကစားပွဲ ရဲ့ အမှတ်များ ကိုသာ အထောက်အကူပြုသည့် ကြိုးစားမှု တစ်ခု မှ အမှတ်ရခဲ့ပါသည်။',\n",
              "  'Portugal never gave up and David Penalva scored a try in the 33rd minute, providing their only points of the match.'],\n",
              " ['အီတလီ သည် ပထမပိုင်း ၌ ၁၆-၅ ဖြင့် ဦးဆောင်ခဲ့ သော်လည်း ပေါ်တူဂီ မှ ဒုတိယပိုင်း တော်တော်များများ တွင် ဂိုးအရေအတွက်ညီစေခဲ့သည် ။',\n",
              "  'Italy led 16-5 at half time but were matched by Portugal for much of the second half.']]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# Convert the dataframe into a list of parallel corpus\n",
        "corpus = df.values.tolist()\n",
        "\n",
        "corpus[0:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVvA32LkS-ob",
        "jp-MarkdownHeadingCollapsed": true,
        "tags": []
      },
      "source": [
        "## 2. Splitting Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mj4hCIv6S-ob",
        "outputId": "51dcc812-a792-472f-e943-a9c5a8be6c03"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19166"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# Check the size of the corpus\n",
        "corpus_size = len(corpus)\n",
        "\n",
        "corpus_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0YAQgZnsS-oc",
        "outputId": "bdddcc79-0064-43a8-8c7f-89c5d5f136a7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(13416, 1916, 3834, 19166)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# Split the corpus into training, validataion and test sets\n",
        "random.shuffle(corpus)\n",
        "\n",
        "train_size = int(corpus_size * 0.7)\n",
        "val_size   = int(corpus_size * 0.1)\n",
        "\n",
        "train = corpus[:train_size]\n",
        "val   = corpus[train_size:(train_size + val_size)]\n",
        "test  = corpus[(train_size + val_size):]\n",
        "\n",
        "len(train), len(val), len(test), len(train)+len(val)+len(test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A31AtVhWS-oc",
        "tags": []
      },
      "source": [
        "## 3. Preprocessing \n",
        "\n",
        "### Tokenizing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cHXZMkNP6hJ-"
      },
      "outputs": [],
      "source": [
        "# Assign the source and target languages\n",
        "SRC_LANGUAGE = 'MY'\n",
        "TRG_LANGUAGE = 'EN'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "35RDGJlrS-od"
      },
      "outputs": [],
      "source": [
        "# Assign place-holders\n",
        "token_transform = {}\n",
        "vocab_transform = {}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install pyidaungsu"
      ],
      "metadata": {
        "id": "OC0h2lOhYej4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qbFRn6249Zm3",
        "outputId": "836ec8d2-75b3-404d-87ec-fe20dbd3cbf0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence:  ကွဲပြားသော အရောင် တစ်ခု ရှိသည့် ဆောင်းပါး အပြောင်းအလဲများကို ပြုလုပ်တဲ့ ၊ မတူညီသော အယ်ဒီတာ တစ်ယောက်စီ ကို ခွင့်ပြုခြင်းသည် ထို အယ်ဒီတာ ၏ စာသား ကို အချိန်ကျော် မှ ထောက်လှမ်းရန်ဖြစ်သည် ။\n",
            "Tokenization:  ['ကွဲပြား', 'သော', 'အရောင်', 'တစ်', 'ခု', 'ရှိ', 'သည့်', 'ဆောင်းပါး', 'အပြောင်း', 'အလဲ', 'များ', 'ကို', 'ပြုလုပ်', 'တဲ့', '၊', 'မ', 'တူညီ', 'သော', 'အယ်ဒီတာ', 'တစ်', 'ယောက်', 'စီ', 'ကို', 'ခွင့်', 'ပြု', 'ခြင်း', 'သည်', 'ထို', 'အယ်ဒီတာ', '၏', 'စာသား', 'ကို', 'အချိန်', 'ကျော်', 'မှ', 'ထောက်လှမ်း', 'ရန်', 'ဖြစ်', 'သည်', '။']\n"
          ]
        }
      ],
      "source": [
        "# Creat the Myanmar tokenizer\n",
        "import pyidaungsu.tokenize as tokenize\n",
        "\n",
        "def myanmar_tokenizer(text):\n",
        "    return tokenize(text, form='word')\n",
        "\n",
        "token_transform[SRC_LANGUAGE] = myanmar_tokenizer\n",
        "\n",
        "print(\"Sentence: \", train[0][0])\n",
        "print(\"Tokenization: \", token_transform[SRC_LANGUAGE](train[0][0]))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!python -m spacy download en_core_web_sm"
      ],
      "metadata": {
        "id": "hkF9NRwOYjX4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_7dOs3eyS-od",
        "outputId": "b2e6e3f1-8e40-492b-fc95-5a5e2e9446c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence:  Each different editor who makes changes to the article has a distinct color, allowing for that editor's text to be tracked over time.\n",
            "Tokenization:  ['Each', 'different', 'editor', 'who', 'makes', 'changes', 'to', 'the', 'article', 'has', 'a', 'distinct', 'color', ',', 'allowing', 'for', 'that', 'editor', \"'s\", 'text', 'to', 'be', 'tracked', 'over', 'time', '.']\n"
          ]
        }
      ],
      "source": [
        "# Creat the English tokenizer\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "token_transform[TRG_LANGUAGE] = get_tokenizer('spacy', language='en_core_web_sm')\n",
        "\n",
        "print(\"Sentence: \", train[0][1])\n",
        "print(\"Tokenization: \", token_transform[TRG_LANGUAGE](train[0][1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Au8iBUjS-od"
      },
      "outputs": [],
      "source": [
        "# helper function to yield list of tokens\n",
        "# here data can be `train` or `val` or `test`\n",
        "def yield_tokens(data, language):\n",
        "    language_index = {SRC_LANGUAGE: 0, TRG_LANGUAGE: 1}\n",
        "\n",
        "    for data_sample in data:\n",
        "        yield token_transform[language](data_sample[language_index[language]]) #either first or second index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jxNmHDfsS-oe"
      },
      "outputs": [],
      "source": [
        "# Define special symbols and indices\n",
        "UNK_IDX, PAD_IDX, SOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
        "# Make sure the tokens are in order of their indices to properly insert them in vocab\n",
        "special_symbols = ['<unk>', '<pad>', '<sos>', '<eos>']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8Z6Q-AKS-oe",
        "tags": []
      },
      "source": [
        "### Numericalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xF9YL5f7S-oe"
      },
      "outputs": [],
      "source": [
        "# Build vocab\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "\n",
        "for ln in [SRC_LANGUAGE, TRG_LANGUAGE]:\n",
        "    # Create torchtext's Vocab object \n",
        "    vocab_transform[ln] = build_vocab_from_iterator(yield_tokens(train, ln), \n",
        "                                                    min_freq=2,   #if not, everything will be treated as UNK\n",
        "                                                    specials=special_symbols,\n",
        "                                                    special_first=True) #indicates whether to insert symbols at the beginning or at the end                                            \n",
        "# Set UNK_IDX as the default index. This index is returned when the token is not found. \n",
        "# If not set, it throws RuntimeError when the queried token is not found in the Vocabulary. \n",
        "for ln in [SRC_LANGUAGE, TRG_LANGUAGE]:\n",
        "    vocab_transform[ln].set_default_index(UNK_IDX)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cmq8vg9ehZzM"
      },
      "outputs": [],
      "source": [
        "# Save vocab\n",
        "import pickle\n",
        "\n",
        "file_path = '/content/nlp-assignments/07-Machine-Translation/vocab_transform.pkl'\n",
        "\n",
        "with open(file_path, 'wb') as file:\n",
        "    pickle.dump(vocab_transform, file)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the saved vocab\n",
        "import pickle\n",
        "\n",
        "file_path = '/content/nlp-assignments/07-Machine-Translation/vocab_transform.pkl'\n",
        "\n",
        "with open(file_path, 'rb') as file:\n",
        "    vocab_transform = pickle.load(file)"
      ],
      "metadata": {
        "id": "EY0mDUzcUoIm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xrd9hgXDS-oe",
        "outputId": "e85ba2a0-37b5-4b4a-9cac-34dcd1afdf05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[414, 909, 479, 0, 479]\n",
            "[978, 18, 11, 0, 11]\n"
          ]
        }
      ],
      "source": [
        "#see some examples\n",
        "print(vocab_transform[SRC_LANGUAGE](['ပြင်သစ်', 'အီတလီ', 'ကုလသမဂ္ဂ', 'ဘလာဘလာ', 'ကုလသမဂ္ဂ']))\n",
        "print(vocab_transform[TRG_LANGUAGE](['here', 'is', 'a', 'unknownword', 'a']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "b7ySki1PS-of",
        "outputId": "5f49d921-0196-4ccd-8a95-7859a84a5e3b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ကုလသမဂ္ဂ'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "#we can reverse it....\n",
        "mapping = vocab_transform[SRC_LANGUAGE].get_itos()\n",
        "\n",
        "mapping[479]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "jcWkWHrTS-of",
        "outputId": "79ddcdc3-a8b2-4d9d-9b4b-3269575b601a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<unk>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "#let's try unknown vocab\n",
        "mapping[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TDSq3RDzS-of",
        "outputId": "47d378f2-2026-4819-e8bd-85955bd5ce88"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('<pad>', '<sos>', '<eos>')"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "#let's try special symbols\n",
        "mapping[1], mapping[2], mapping[3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CF1irvO-S-of",
        "outputId": "61cebf8a-8718-426b-f2ba-48e3597e04b5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11102"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "#check unique vocabularies\n",
        "len(mapping)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A3Z32aZgS-of",
        "tags": []
      },
      "source": [
        "## 4. Preparing Dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KLUEGwErS-og"
      },
      "outputs": [],
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# helper function to club together sequential operations\n",
        "def sequential_transforms(*transforms):\n",
        "    def func(txt_input):\n",
        "        for transform in transforms:\n",
        "            txt_input = transform(txt_input)\n",
        "        return txt_input\n",
        "    return func\n",
        "\n",
        "# function to add BOS/EOS and create tensor for input sequence indices\n",
        "def tensor_transform(token_ids):\n",
        "    return torch.cat((torch.tensor([SOS_IDX]), \n",
        "                      torch.tensor(token_ids), \n",
        "                      torch.tensor([EOS_IDX])))\n",
        "\n",
        "# src and trg language text transforms to convert raw strings into tensors indices\n",
        "text_transform = {}\n",
        "for ln in [SRC_LANGUAGE, TRG_LANGUAGE]:\n",
        "    text_transform[ln] = sequential_transforms(token_transform[ln], #Tokenization\n",
        "                                               vocab_transform[ln], #Numericalization\n",
        "                                               tensor_transform) # Add BOS/EOS and create tensor\n",
        "\n",
        "\n",
        "# function to collate data samples into batch tesors\n",
        "def collate_batch(batch):\n",
        "    src_batch, src_len_batch, trg_batch = [], [], []\n",
        "    for src_sample, trg_sample in batch:\n",
        "        processed_text = text_transform[SRC_LANGUAGE](src_sample.rstrip(\"\\n\"))\n",
        "        src_batch.append(processed_text)\n",
        "        trg_batch.append(text_transform[TRG_LANGUAGE](trg_sample.rstrip(\"\\n\")))\n",
        "        src_len_batch.append(processed_text.size(0))\n",
        "\n",
        "    src_batch = pad_sequence(src_batch, padding_value=PAD_IDX)\n",
        "    trg_batch = pad_sequence(trg_batch, padding_value=PAD_IDX)\n",
        "    return src_batch, torch.tensor(src_len_batch, dtype=torch.int64), trg_batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NWEmK5e5S-og"
      },
      "outputs": [],
      "source": [
        "# Create traning, validataion and test dataloaders\n",
        "batch_size = 16\n",
        "\n",
        "train_loader = DataLoader(train, batch_size=batch_size,\n",
        "                              shuffle=True, collate_fn=collate_batch)\n",
        "val_loader = DataLoader(val, batch_size=batch_size,\n",
        "                              shuffle=True, collate_fn=collate_batch)\n",
        "test_loader  = DataLoader(test, batch_size=batch_size,\n",
        "                             shuffle=True, collate_fn=collate_batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wks132OvS-og",
        "outputId": "0f6baee4-d5ea-467e-ff70-b7db6150a301"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Myanmar shape:  torch.Size([95, 16])\n",
            "English shape:  torch.Size([64, 16])\n"
          ]
        }
      ],
      "source": [
        "# Test the train_loader\n",
        "for my, _, en in train_loader:\n",
        "    break\n",
        "\n",
        "print(\"Myanmar shape: \", my.shape)  # (seq len, batch_size)\n",
        "print(\"English shape: \", en.shape)   # (seq len, batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-2e1hdCS-oh"
      },
      "source": [
        "## 5. Modeling\n",
        "\n",
        "### Encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b7PU-x03S-oh"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim, hid_dim, dropout):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
        "        self.rnn = nn.GRU(emb_dim, hid_dim, bidirectional = True)\n",
        "        self.fc = nn.Linear(hid_dim * 2, hid_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, src, src_len):\n",
        "        \n",
        "        #src = [src len, batch size]\n",
        "        #src_len = [batch size]\n",
        "        \n",
        "        embedded = self.dropout(self.embedding(src))\n",
        "        #embedded = [src len, batch size, emb dim]\n",
        "                \n",
        "        #need to explicitly put lengths on cpu!\n",
        "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, src_len.to('cpu'), enforce_sorted=False)\n",
        "                \n",
        "        packed_outputs, hidden = self.rnn(packed_embedded)        \n",
        "        #packed_outputs is a packed sequence containing all hidden states\n",
        "        #hidden is now from the final non-padded element in the batch\n",
        "            \n",
        "        outputs, _ = nn.utils.rnn.pad_packed_sequence(packed_outputs) \n",
        "        #outputs is now a non-packed sequence, all hidden states obtained\n",
        "        #  when the input is a pad token are all zeros\n",
        "            \n",
        "        #outputs = [src len, batch size, hid dim * num directions]\n",
        "        #hidden = [n layers * num directions, batch size, hid dim]\n",
        "        \n",
        "        #hidden is stacked [forward_1, backward_1, forward_2, backward_2, ...]\n",
        "        #outputs are always from the last layer\n",
        "        \n",
        "        #hidden [-2, :, : ] is the last of the forwards RNN \n",
        "        #hidden [-1, :, : ] is the last of the backwards RNN\n",
        "        \n",
        "        #initial decoder hidden is final hidden state of the forwards and backwards \n",
        "        #  encoder RNNs fed through a linear layer\n",
        "        hidden = torch.tanh(self.fc(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)))\n",
        "        \n",
        "        #outputs = [src len, batch size, hid dim * 2]\n",
        "        #hidden = [batch size, hid dim]\n",
        "        \n",
        "        return outputs, hidden"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FdkBusWVS-oh"
      },
      "source": [
        "### General Attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gVmS2nMVS-oh"
      },
      "outputs": [],
      "source": [
        "class GeneralAttention(nn.Module):\n",
        "    def __init__(self, hid_dim):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.v = nn.Linear(hid_dim, 1, bias = False)\n",
        "        self.W = nn.Linear(hid_dim,     hid_dim) #for decoder\n",
        "        self.U = nn.Linear(hid_dim * 2, hid_dim) #for encoder outputs\n",
        "                \n",
        "    def forward(self, hidden, encoder_outputs, mask):\n",
        "        \n",
        "        batch_size = encoder_outputs.shape[1]\n",
        "\n",
        "        hidden = hidden.unsqueeze(1).repeat(1, 1, 2)\n",
        "\n",
        "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
        "        \n",
        "        energy = torch.bmm(hidden, encoder_outputs.transpose(1, 2))\n",
        "        \n",
        "        attention = energy.squeeze(1)\n",
        "\n",
        "        attention = attention.masked_fill(mask, -1e10)\n",
        "        \n",
        "        return F.softmax(attention, dim = 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Additive Attention"
      ],
      "metadata": {
        "id": "cbxh7DLqBvnd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AdditiveAttention(nn.Module):\n",
        "    def __init__(self, hid_dim):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.v = nn.Linear(hid_dim, 1, bias = False)\n",
        "        self.W = nn.Linear(hid_dim,     hid_dim) #for decoder\n",
        "        self.U = nn.Linear(hid_dim * 2, hid_dim) #for encoder outputs\n",
        "                \n",
        "    def forward(self, hidden, encoder_outputs, mask):\n",
        "        \n",
        "        batch_size = encoder_outputs.shape[1]\n",
        "\n",
        "        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
        "\n",
        "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
        "        \n",
        "        energy = torch.tanh(self.W(hidden) + self.U(encoder_outputs))\n",
        "        \n",
        "        attention = self.v(energy).squeeze(2)\n",
        "\n",
        "        attention = attention.masked_fill(mask, -1e10)\n",
        "        \n",
        "        return F.softmax(attention, dim = 1)"
      ],
      "metadata": {
        "id": "Pt-gzlrDB2DR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Multiplicative Attention"
      ],
      "metadata": {
        "id": "uMaFFeYMB2kP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiplicativeAttention(nn.Module):\n",
        "    def __init__(self, hid_dim):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.v = nn.Linear(hid_dim, 1, bias = False)\n",
        "        self.W = nn.Linear(hid_dim,     hid_dim) #for decoder\n",
        "        self.U = nn.Linear(hid_dim * 2, hid_dim) #for encoder outputs\n",
        "                \n",
        "    def forward(self, hidden, encoder_outputs, mask):\n",
        "        \n",
        "        batch_size = encoder_outputs.shape[1]\n",
        "        \n",
        "        wh = self.W(hidden).unsqueeze(1).repeat(1, 1, 2)\n",
        "\n",
        "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
        "        \n",
        "        energy = torch.bmm(wh, encoder_outputs.transpose(1, 2))\n",
        "        \n",
        "        attention = energy.squeeze(1)\n",
        "\n",
        "        attention = attention.masked_fill(mask, -1e10)\n",
        "        \n",
        "        return F.softmax(attention, dim = 1)"
      ],
      "metadata": {
        "id": "Lv2Yqn6UB7JL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3eVxfipYS-oi",
        "outputId": "4d188187-2fe7-47e9-f458-fc853e71f33e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[           9, -10000000000,            7,            2, -10000000000,\n",
            "         -10000000000],\n",
            "        [          99, -10000000000, -10000000000,            0,            8,\n",
            "                    9]])\n"
          ]
        }
      ],
      "source": [
        "#example of masked_fill\n",
        "#reall that 1 is pad_idx\n",
        "x = torch.tensor([ [9, 1, 7, 2, 1, 1], [99, 1, 1, 0, 8, 9] ])\n",
        "\n",
        "mask = (x == PAD_IDX)\n",
        "\n",
        "x.masked_fill_(mask, -1e10)\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ErC6YwDSS-oi",
        "tags": []
      },
      "source": [
        "### Decoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FjjCBLMaS-oi"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, emb_dim, hid_dim, dropout, attention):\n",
        "        super().__init__()\n",
        "\n",
        "        self.output_dim = output_dim\n",
        "        self.attention = attention\n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
        "        self.gru = nn.GRU((hid_dim * 2) + emb_dim, hid_dim)\n",
        "        self.fc = nn.Linear((hid_dim * 2) + hid_dim + emb_dim, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, input, hidden, encoder_outputs, mask):\n",
        "             \n",
        "        #input = [batch size]\n",
        "        #hidden = [batch size, hid dim]\n",
        "        #encoder_outputs = [src len, batch size, hid dim * 2]\n",
        "        #mask = [batch size, src len]\n",
        "        \n",
        "        input = input.unsqueeze(0)\n",
        "        #input = [1, batch size]\n",
        "        \n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "        #embedded = [1, batch size, emb dim]\n",
        "        \n",
        "        a = self.attention(hidden, encoder_outputs, mask)\n",
        "        #a = [batch size, src len]\n",
        "        \n",
        "        a = a.unsqueeze(1)\n",
        "        #a = [batch size, 1, src len]\n",
        "        \n",
        "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
        "        #encoder_outputs = [batch size, src len, hid dim * 2]\n",
        "        \n",
        "        weighted = torch.bmm(a, encoder_outputs)\n",
        "        #weighted = [batch size, 1, hid dim * 2]\n",
        "        \n",
        "        weighted = weighted.permute(1, 0, 2)\n",
        "        #weighted = [1, batch size, hid dim * 2]\n",
        "        \n",
        "        rnn_input = torch.cat((embedded, weighted), dim = 2)\n",
        "        #rnn_input = [1, batch size, (hid dim * 2) + emb dim]\n",
        "            \n",
        "        output, hidden = self.gru(rnn_input, hidden.unsqueeze(0))\n",
        "        #output = [seq len, batch size, dec hid dim * n directions]\n",
        "        #hidden = [n layers * n directions, batch size, hid dim]\n",
        "        \n",
        "        #seq len, n layers and n directions will always be 1 in this decoder, therefore:\n",
        "        #output = [1, batch size, hid dim]\n",
        "        #hidden = [1, batch size, hid dim]\n",
        "        #this also means that output == hidden\n",
        "        assert (output == hidden).all()\n",
        "        \n",
        "        embedded = embedded.squeeze(0)\n",
        "        output = output.squeeze(0)\n",
        "        weighted = weighted.squeeze(0)\n",
        "        \n",
        "        prediction = self.fc(torch.cat((output, weighted, embedded), dim = 1))\n",
        "        #prediction = [batch size, output dim]\n",
        "        \n",
        "        return prediction, hidden.squeeze(0), a.squeeze(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Afov6lRGS-oi"
      },
      "source": [
        "### Seq2Seq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "98fVboXCS-oi"
      },
      "outputs": [],
      "source": [
        "class Seq2SeqPackedAttention(nn.Module):\n",
        "    def __init__(self, encoder, decoder, src_pad_idx, device):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.src_pad_idx = src_pad_idx\n",
        "        self.device = device\n",
        "        \n",
        "    def create_mask(self, src):\n",
        "        mask = (src == self.src_pad_idx).permute(1, 0)  #permute so it's the same shape as attention\n",
        "        return mask\n",
        "        \n",
        "    def forward(self, src, src_len, trg, teacher_forcing_ratio = 0.5):\n",
        "        \n",
        "        #src = [src len, batch size]\n",
        "        #src_len = [batch size]\n",
        "        #trg = [trg len, batch size]\n",
        "        #teacher_forcing_ratio is probability to use teacher forcing\n",
        "        #e.g. if teacher_forcing_ratio is 0.75 we use teacher forcing 75% of the time\n",
        "                    \n",
        "        batch_size = src.shape[1]\n",
        "        trg_len = trg.shape[0]\n",
        "        trg_vocab_size = self.decoder.output_dim\n",
        "        \n",
        "        #tensor to store decoder outputs\n",
        "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
        "        \n",
        "        #tensor to store attentiont outputs from decoder\n",
        "        attentions = torch.zeros(trg_len, batch_size, src.shape[0]).to(self.device)\n",
        "        \n",
        "        #encoder_outputs is all hidden states of the input sequence, back and forwards\n",
        "        #hidden is the final forward and backward hidden states, passed through a linear layer\n",
        "        encoder_outputs, hidden = self.encoder(src, src_len)\n",
        "                \n",
        "        #first input to the decoder is the <sos> tokens\n",
        "        input_ = trg[0,:]\n",
        "        \n",
        "        mask = self.create_mask(src)\n",
        "        #mask = [batch size, src len]\n",
        "                \n",
        "        for t in range(1, trg_len):\n",
        "            \n",
        "            #insert input token embedding, previous hidden state, all encoder hidden states \n",
        "            #  and mask\n",
        "            #receive output tensor (predictions) and new hidden state\n",
        "            output, hidden, attention = self.decoder(input_, hidden, encoder_outputs, mask)\n",
        "            #output    = [batch size, output dim]\n",
        "            #hidden    = [batch size, hid dim]\n",
        "            #attention = [batch size, src len]\n",
        "            \n",
        "            #place predictions in a tensor holding predictions for each token\n",
        "            outputs[t] = output\n",
        "            \n",
        "            #place attentions in a tensor holding attention for each token\n",
        "            attentions[t] = attention\n",
        "            \n",
        "            #decide if we are going to use teacher forcing or not\n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "            \n",
        "            #get the highest predicted token from our predictions\n",
        "            top1 = output.argmax(1) \n",
        "            \n",
        "            #if teacher forcing, use actual next token as next input\n",
        "            #if not, use predicted token\n",
        "            input_ = trg[t] if teacher_force else top1\n",
        "            \n",
        "        return outputs, attentions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LshZSBUvS-oi",
        "tags": []
      },
      "source": [
        "## 6. Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "484hkCNAS-oj"
      },
      "outputs": [],
      "source": [
        "def initialize_weights(m):\n",
        "    for name, param in m.named_parameters():\n",
        "        if 'weight' in name:\n",
        "            nn.init.normal_(param.data, mean=0, std=0.01)\n",
        "        else:\n",
        "            nn.init.constant_(param.data, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jsLA4FuaS-oj",
        "outputId": "f2874ebd-773c-459c-bfe1-68ab2729d21a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Seq2SeqPackedAttention(\n",
              "  (encoder): Encoder(\n",
              "    (embedding): Embedding(11102, 64)\n",
              "    (rnn): GRU(64, 128, bidirectional=True)\n",
              "    (fc): Linear(in_features=256, out_features=128, bias=True)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (attention): Attention(\n",
              "      (v): Linear(in_features=128, out_features=1, bias=False)\n",
              "      (W): Linear(in_features=128, out_features=128, bias=True)\n",
              "      (U): Linear(in_features=256, out_features=128, bias=True)\n",
              "    )\n",
              "    (embedding): Embedding(14382, 64)\n",
              "    (gru): GRU(320, 128)\n",
              "    (fc): Linear(in_features=448, out_features=14382, bias=True)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "input_dim   = len(vocab_transform[SRC_LANGUAGE])\n",
        "output_dim  = len(vocab_transform[TRG_LANGUAGE])\n",
        "emb_dim     = 64  \n",
        "hid_dim     = 128  \n",
        "dropout     = 0.5\n",
        "SRC_PAD_IDX = PAD_IDX\n",
        "\n",
        "attn = Attention(hid_dim)\n",
        "enc  = Encoder(input_dim,  emb_dim,  hid_dim, dropout)\n",
        "dec  = Decoder(output_dim, emb_dim,  hid_dim, dropout, attn)\n",
        "\n",
        "model = Seq2SeqPackedAttention(enc, dec, SRC_PAD_IDX, device).to(device)\n",
        "model.apply(initialize_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3bhEGnmoS-oj",
        "outputId": "1af45dbd-f694-4344-b544-5d517d371d71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "710528\n",
            " 24576\n",
            " 49152\n",
            "   384\n",
            "   384\n",
            " 24576\n",
            " 49152\n",
            "   384\n",
            "   384\n",
            " 32768\n",
            "   128\n",
            "   128\n",
            " 16384\n",
            "   128\n",
            " 32768\n",
            "   128\n",
            "920448\n",
            "122880\n",
            " 49152\n",
            "   384\n",
            "   384\n",
            "6443136\n",
            " 14382\n",
            "______\n",
            "8492718\n"
          ]
        }
      ],
      "source": [
        "# Print the number of model parameters\n",
        "def count_parameters(model):\n",
        "    params = [p.numel() for p in model.parameters() if p.requires_grad]\n",
        "    for item in params:\n",
        "        print(f'{item:>6}')\n",
        "    print(f'______\\n{sum(params):>6}')\n",
        "    \n",
        "count_parameters(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xZhXqrFTS-oj"
      },
      "outputs": [],
      "source": [
        "# Set the training hyperparameters\n",
        "import torch.optim as optim\n",
        "\n",
        "lr = 0.001\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = PAD_IDX) #combine softmax with cross entropy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S61OnhqSS-oj"
      },
      "outputs": [],
      "source": [
        "# Create the function for training\n",
        "def train(model, loader, optimizer, criterion, clip, loader_length):\n",
        "    \n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    \n",
        "    for src, src_length, trg in loader:\n",
        "        \n",
        "        src = src.to(device)\n",
        "        trg = trg.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        output, attentions = model(src, src_length, trg)\n",
        "        \n",
        "        #trg    = [trg len, batch size]\n",
        "        #output = [trg len, batch size, output dim]\n",
        "        output_dim = output.shape[-1]\n",
        "        \n",
        "        #the loss function only works on 2d inputs with 1d targets thus we need to flatten each of them\n",
        "        output = output[1:].view(-1, output_dim)\n",
        "        trg    = trg[1:].view(-1)\n",
        "        #trg    = [(trg len - 1) * batch size]\n",
        "        #output = [(trg len - 1) * batch size, output dim]\n",
        "        \n",
        "        loss = criterion(output, trg)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        #clip the gradients to prevent them from exploding (a common issue in RNNs)\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / loader_length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "up78lf8nS-ok"
      },
      "outputs": [],
      "source": [
        "# Create the function for evaluation\n",
        "def evaluate(model, loader, criterion, loader_length):\n",
        "        \n",
        "    #turn off dropout (and batch norm if used)\n",
        "    model.eval()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for src, src_length, trg in loader:\n",
        "        \n",
        "            src = src.to(device)\n",
        "            trg = trg.to(device)\n",
        "\n",
        "            output, attentions = model(src, src_length, trg, 0) #turn off teacher forcing\n",
        "\n",
        "            #trg    = [trg len, batch size]\n",
        "            #output = [trg len, batch size, output dim]\n",
        "\n",
        "            output_dim = output.shape[-1]\n",
        "            \n",
        "            output = output[1:].view(-1, output_dim)\n",
        "            trg = trg[1:].view(-1)\n",
        "\n",
        "            #trg    = [(trg len - 1) * batch size]\n",
        "            #output = [(trg len - 1) * batch size, output dim]\n",
        "\n",
        "            loss = criterion(output, trg)\n",
        "            \n",
        "            epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / loader_length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s_gNRrfaS-ok"
      },
      "outputs": [],
      "source": [
        "# Find the lengths of the dataloaders\n",
        "#train_loader_length = len(list(iter(train_loader)))\n",
        "#val_loader_length   = len(list(iter(val_loader)))\n",
        "#test_loader_length  = len(list(iter(test_loader)))\n",
        "\n",
        "train_loader_length = 210\n",
        "val_loader_length   = 30\n",
        "test_loader_length  = 60"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hb4O0uXLS-ok"
      },
      "outputs": [],
      "source": [
        "# Create the function to calculate training epoch time\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gcbCauL7Q-pX"
      },
      "outputs": [],
      "source": [
        "# Create the folder to save models\n",
        "import os\n",
        "from os import path\n",
        "\n",
        "if path.exists('/content/nlp-assignments/07-Machine-Translation/models') == False:\n",
        "  os.mkdir('/content/nlp-assignments/07-Machine-Translation/models')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 849
        },
        "id": "2k9QRbqYS-ok",
        "outputId": "b5ddfbef-84eb-49bc-823f-21b76c9a957c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01 | Time: 4m 0s\n",
            "\tTrain Loss: 26.531 | Train PPL: 332877939178.335\n",
            "\t Val. Loss: 26.450 |  Val. PPL: 307046159333.693\n",
            "Epoch: 02 | Time: 3m 50s\n",
            "\tTrain Loss: 24.732 | Train PPL: 55053876166.375\n",
            "\t Val. Loss: 25.799 |  Val. PPL: 160133271304.901\n",
            "Epoch: 03 | Time: 3m 49s\n",
            "\tTrain Loss: 23.742 | Train PPL: 20459610686.448\n",
            "\t Val. Loss: 25.403 |  Val. PPL: 107791771619.762\n",
            "Epoch: 04 | Time: 3m 48s\n",
            "\tTrain Loss: 22.866 | Train PPL: 8524331303.844\n",
            "\t Val. Loss: 25.177 |  Val. PPL: 85956718582.322\n",
            "Epoch: 05 | Time: 3m 48s\n",
            "\tTrain Loss: 22.047 | Train PPL: 3759064534.576\n",
            "\t Val. Loss: 24.908 |  Val. PPL: 65706728234.211\n",
            "Epoch: 06 | Time: 3m 53s\n",
            "\tTrain Loss: 21.328 | Train PPL: 1831673984.756\n",
            "\t Val. Loss: 24.902 |  Val. PPL: 65269403088.088\n",
            "Epoch: 07 | Time: 3m 49s\n",
            "\tTrain Loss: 20.678 | Train PPL: 955278680.115\n",
            "\t Val. Loss: 24.802 |  Val. PPL: 59097713016.264\n",
            "Epoch: 08 | Time: 3m 54s\n",
            "\tTrain Loss: 20.012 | Train PPL: 490968391.011\n",
            "\t Val. Loss: 24.802 |  Val. PPL: 59089409897.202\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-f464fc1d9b74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mval_loss\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-1d532b228a36>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, loader, optimizer, criterion, clip, loader_length)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m#clip the gradients to prevent them from exploding (a common issue in RNNs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    486\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m             )\n\u001b[0;32m--> 488\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    489\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    198\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 352.00 MiB (GPU 0; 14.75 GiB total capacity; 11.98 GiB already allocated; 140.81 MiB free; 13.42 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "best_val_loss = float('inf')\n",
        "num_epochs = 10\n",
        "clip       = 1\n",
        "\n",
        "save_path = f'/content/nlp-assignments/07-Machine-Translation/models/{model.__class__.__name__}.pt'\n",
        "\n",
        "train_losses = []\n",
        "val_losses   = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    \n",
        "    start_time = time.time()\n",
        "\n",
        "    train_loss = train(model, train_loader, optimizer, criterion, clip, train_loader_length)\n",
        "    val_loss   = evaluate(model, val_loader, criterion, val_loader_length)\n",
        "    \n",
        "    #for plotting\n",
        "    train_losses.append(train_loss)\n",
        "    val_losses.append(val_loss)\n",
        "    \n",
        "    end_time = time.time()\n",
        "    \n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    \n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        torch.save(model.state_dict(), save_path)\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
        "    print(f'\\t Val. Loss: {val_loss:.3f} |  Val. PPL: {math.exp(val_loss):7.3f}')\n",
        "    \n",
        "    #lower perplexity is better"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "id": "-I-m_G2yS-ol",
        "outputId": "985f7c03-8b29-481f-c47b-4bbbdc8b9960"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-4d7fa25cba32>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'train loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'val loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_losses' is not defined"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x216 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "fig = plt.figure(figsize=(5, 3))\n",
        "ax = fig.add_subplot(1, 1, 1)\n",
        "ax.plot(train_losses, label = 'train loss')\n",
        "ax.plot(val_losses, label = 'val loss')\n",
        "plt.legend()\n",
        "ax.set_xlabel('updates')\n",
        "ax.set_ylabel('loss')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3cAom0rS-ol",
        "outputId": "dc00a6e4-3891-4dcb-d5ca-e0c55f7d4ed0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| Test Loss: 24.756 | Test PPL: 56430643542.749 |\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model with the test set\n",
        "model.load_state_dict(torch.load(save_path))\n",
        "test_loss = evaluate(model, test_loader, criterion, test_loader_length)\n",
        "\n",
        "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R45qd6XVS-ol"
      },
      "source": [
        "## 7. Testing on Random Samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "od9K4YAqS-ol"
      },
      "outputs": [],
      "source": [
        "sample = corpus[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3fNPlwMS-ol",
        "outputId": "c728681f-6da3-4282-def2-bb96c2b66d2a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('အမေရိကန် နှင့် ဩစတေးလျ တွင် တက်ကြွသော ရုံးခွဲ များ နှင့် နယူးဇီလန် တွင် အဖွဲ့ဝင်များ မှာ ၂၀၀၀ နီးပါး ရှိပါသည် ။',\n",
              " 'There are approximately 2000 members in New Zealand and active branches in the US and Australia.')"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "sample[0], sample[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XdBQD-zOS-ol",
        "outputId": "9ab508e9-e5d3-48a0-a5db-d63c894041fb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([   2,   66,   17, 1536,   14, 1380,   10,  307,  398,    9,   17,  369,\n",
              "          14,   63,  117,    9,   31, 1132,  447,   18,   22,    4,    8,    3],\n",
              "       device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "src_text = text_transform[SRC_LANGUAGE](sample[0]).to(device)\n",
        "src_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTGMrxL-S-om",
        "outputId": "839728d3-1f19-46f9-ce52-3da461b457ac"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([   2,  201,   31,  456,  793,  190,   10,   77,  209,    9, 2035, 5437,\n",
              "          10,    4,  157,    9,  172,    6,    3], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "trg_text = text_transform[TRG_LANGUAGE](sample[1]).to(device)\n",
        "trg_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ETmtpNP7S-om"
      },
      "outputs": [],
      "source": [
        "src_text = src_text.reshape(-1, 1)  #because batch_size is 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O05tDi5hS-om"
      },
      "outputs": [],
      "source": [
        "trg_text = trg_text.reshape(-1, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_KNr2gMS-om",
        "outputId": "0d667c22-dadf-412a-d5e1-3d49c1764773"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([24, 1]), torch.Size([19, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "source": [
        "src_text.shape, trg_text.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2cB-LlnHS-om"
      },
      "outputs": [],
      "source": [
        "text_length = torch.tensor([src_text.size(0)]).to(dtype=torch.int64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QycUn8YiS-om"
      },
      "outputs": [],
      "source": [
        "model.load_state_dict(torch.load(save_path))\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    output, attentions = model(src_text, text_length, trg_text, 0) #turn off teacher forcing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6fA-83RuS-om",
        "outputId": "cbf10e4d-9e4b-4a12-d4f4-40d39ac085e8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([19, 1, 14382])"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ],
      "source": [
        "output.shape #trg_len, batch_size, trg_output_dim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qrouCUaq2U40"
      },
      "source": [
        "Since batch size is 1, we just take off that dimension"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6mODv39xS-on"
      },
      "outputs": [],
      "source": [
        "output = output.squeeze(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j-ksFyJnS-on",
        "outputId": "45173987-334d-4435-ddc2-bcb9a9e8c429"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([19, 14382])"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ],
      "source": [
        "output.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nywvdJ72fed"
      },
      "source": [
        "We shall remove the first token since it's zeroes anyway"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ciAz2R-CS-on",
        "outputId": "aa6c5dde-f043-48a7-d268-e158d8e51622"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([18, 14382])"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ],
      "source": [
        "output = output[1:]\n",
        "output.shape #trg_len, trg_output_dim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-a5TlSh2oyp"
      },
      "source": [
        "Then we just take the top token with highest probabilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WfdvvDofS-on"
      },
      "outputs": [],
      "source": [
        "output_max = output.argmax(1) #returns max indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wm_i1iZGS-on",
        "outputId": "06269bc2-6d14-4340-9335-009b386f8c59"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 14,  77, 209,   9,  24,  35,   4,  10,   4,   9,   4,   4,   9,   4,\n",
              "          6,   3,   6,   3], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ],
      "source": [
        "output_max"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JyMePvyN2vGA"
      },
      "source": [
        "Get the mapping of the target language"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kFzeKwMuS-on"
      },
      "outputs": [],
      "source": [
        "mapping = vocab_transform[TRG_LANGUAGE].get_itos()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aTu91y3PS-oo",
        "outputId": "e47e7512-587d-4fc5-bf19-6627dcdb0115"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The\n",
            "New\n",
            "Zealand\n",
            "and\n",
            "have\n",
            "been\n",
            "the\n",
            "in\n",
            "the\n",
            "and\n",
            "the\n",
            "the\n",
            "and\n",
            "the\n",
            ".\n",
            "<eos>\n",
            ".\n",
            "<eos>\n"
          ]
        }
      ],
      "source": [
        "for token in output_max:\n",
        "    print(mapping[token.item()])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jPDUHyJLS-oo"
      },
      "source": [
        "## 8. Attention\n",
        "\n",
        "Let's display the attentions to understand how the source text links with the generated text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_LJKWXNyS-oo",
        "outputId": "fd4e761b-09ef-4e66-91aa-ecb37366d58c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([19, 1, 24])"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ],
      "source": [
        "attentions.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BD4v2bHNS-oo",
        "outputId": "08f3072a-f28e-4b97-c7f6-a03c2a7c3714",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<sos>',\n",
              " 'အမေရိကန်',\n",
              " 'နှင့်',\n",
              " 'ဩစတေးလျ',\n",
              " 'တွင်',\n",
              " 'တက်ကြွ',\n",
              " 'သော',\n",
              " 'ရုံး',\n",
              " 'ခွဲ',\n",
              " 'များ',\n",
              " 'နှင့်',\n",
              " 'နယူးဇီလန်',\n",
              " 'တွင်',\n",
              " 'အဖွဲ့',\n",
              " 'ဝင်',\n",
              " 'များ',\n",
              " 'မှာ',\n",
              " '၂၀၀၀',\n",
              " 'နီးပါး',\n",
              " 'ရှိ',\n",
              " 'ပါ',\n",
              " 'သည်',\n",
              " '။',\n",
              " '<eos>']"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ],
      "source": [
        "src_tokens = ['<sos>'] + token_transform[SRC_LANGUAGE](sample[0]) + ['<eos>']\n",
        "src_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wBwZORT9S-oo"
      },
      "outputs": [],
      "source": [
        "trg_tokens = ['<sos>'] + [mapping[token.item()] for token in output_max]\n",
        "trg_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-MkeMlx1S-oo"
      },
      "outputs": [],
      "source": [
        "import matplotlib.ticker as ticker\n",
        "\n",
        "def display_attention(sentence, translation, attention):\n",
        "    \n",
        "    fig = plt.figure(figsize=(10,10))\n",
        "    ax = fig.add_subplot(111)\n",
        "    \n",
        "    attention = attention.squeeze(1).cpu().detach().numpy()\n",
        "    \n",
        "    cax = ax.matshow(attention, cmap='bone')\n",
        "   \n",
        "    ax.tick_params(labelsize=10)\n",
        "    \n",
        "    y_ticks =  [''] + translation\n",
        "    x_ticks =  [''] + sentence \n",
        "     \n",
        "    ax.set_xticklabels(x_ticks, rotation=45)\n",
        "    ax.set_yticklabels(y_ticks)\n",
        "\n",
        "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "    plt.show()\n",
        "    plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mflor_QqS-oo",
        "outputId": "e27937ac-b7d8-416b-b246-a0ac7aff3a84"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_2592381/59549304.py:17: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
            "  ax.set_xticklabels(x_ticks, rotation=45)\n",
            "/tmp/ipykernel_2592381/59549304.py:18: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
            "  ax.set_yticklabels(y_ticks)\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x1000 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display_attention(src_tokens, trg_tokens, attentions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CxQp1fJGS-op"
      },
      "source": [
        "## Conclusion\n",
        "\n",
        "Nice!  We get the similar perplexity but with much faster computations, thanks to packed sequences and masking.   We also can see attention by our eyes, so we should believe it now!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "dsai",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.2"
    },
    "vscode": {
      "interpreter": {
        "hash": "0f2c79af21be9d001248940c049b6176cf8bfb45cabf7aa85848f5cea0f590f6"
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}