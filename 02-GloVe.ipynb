{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1.24.0', '1.12.1')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.__version__, torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.6.2'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib\n",
    "matplotlib.__version__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#specify the sentences / corpus\n",
    "#corpus is defined as a set of documents\n",
    "#document is basically a bunch of sentence(s)\n",
    "corpus = [\"apple banana fruit\", \"banana apple fruit\", \"banana fruit apple\", \n",
    "          \"dog cat animal\", \"cat dog animal\", \"cat animal dog\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['apple', 'banana', 'fruit'],\n",
       " ['banana', 'apple', 'fruit'],\n",
       " ['banana', 'fruit', 'apple'],\n",
       " ['dog', 'cat', 'animal'],\n",
       " ['cat', 'dog', 'animal'],\n",
       " ['cat', 'animal', 'dog']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1. tokenize\n",
    "#usually you use spaCy / NLTK to tokenize (but we gonna do this later on, we gonna have spaCy)\n",
    "corpus_tokenized = [sent.split(\" \") for sent in corpus]\n",
    "corpus_tokenized  #we called each of this as \"tokens\", NOT words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. numericalize\n",
    "\n",
    "#2.1 get all the unique words\n",
    "#we want to flatten this (basically merge all list)\n",
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "vocabs  = list(set(flatten(corpus_tokenized)))  #vocabs is a term defining all unique words your system know"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.2 assign id to all these vocabs\n",
    "word2index = {v: idx for idx, v in enumerate(vocabs)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'apple': 0, 'fruit': 1, 'dog': 2, 'banana': 3, 'cat': 4, 'animal': 5}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add <UNK>, which is a very normal token exists in the world\n",
    "vocabs.append('<UNK>') #chaky, can it be ##UNK, or UNKKKKKK, or anything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we have a way to know what is the id of <UNK>\n",
    "word2index['<UNK>'] = 6  #usually <UNK> is 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'apple',\n",
       " 1: 'fruit',\n",
       " 2: 'dog',\n",
       " 3: 'banana',\n",
       " 4: 'cat',\n",
       " 5: 'animal',\n",
       " 6: '<UNK>'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create index2word dictionary\n",
    "#2 min    \n",
    "index2word = {v:k for k, v in word2index.items()}\n",
    "\n",
    "index2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['apple', 'fruit', 'dog', 'banana', 'cat', 'animal', '<UNK>']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Co-occurrence matrix\n",
    "\n",
    "Count the occurrences of pair of words using window size of 1 (you can use 2, 3, 4, up to you.)\n",
    "\n",
    "E.g., Dog loves to eat meat.     \n",
    "\n",
    "['dog', 'loves', 1], ['loves', 'to', 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use Counter to first count stuffs\n",
    "from collections import Counter\n",
    "\n",
    "# print(corpus_tokenized)\n",
    "\n",
    "#count the frequency of each word....\n",
    "#we somehow need this to calculate the probability Pi\n",
    "X_i = Counter(flatten(corpus_tokenized)) #merge all list....(flatten is a function I define.....)\n",
    "\n",
    "# X_i['apple'] #get the probability of apple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['apple', 'banana', 'fruit'],\n",
       " ['banana', 'apple', 'fruit'],\n",
       " ['banana', 'fruit', 'apple'],\n",
       " ['dog', 'cat', 'animal'],\n",
       " ['cat', 'dog', 'animal'],\n",
       " ['cat', 'animal', 'dog']]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a skipgram of window size 1\n",
    "skip_grams = []\n",
    "\n",
    "#loop through each corpus\n",
    "for sent in corpus_tokenized:  #['apple', 'banana', 'fruit']\n",
    "    #loop through each word from 1 to n-1 (because 0 and n has no context window)\n",
    "    for i in range(1, len(sent)-1):\n",
    "        target  = sent[i]\n",
    "        context = [sent[i+1], sent[i-1]]\n",
    "        #append(i, i+1) and append(i, i-1)\n",
    "        for c in context:\n",
    "            skip_grams.append((target, c))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['apple', 'banana', 'fruit'],\n",
       " ['banana', 'apple', 'fruit'],\n",
       " ['banana', 'fruit', 'apple'],\n",
       " ['dog', 'cat', 'animal'],\n",
       " ['cat', 'dog', 'animal'],\n",
       " ['cat', 'animal', 'dog']]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('banana', 'fruit'),\n",
       " ('banana', 'apple'),\n",
       " ('apple', 'fruit'),\n",
       " ('apple', 'banana'),\n",
       " ('fruit', 'apple'),\n",
       " ('fruit', 'banana'),\n",
       " ('cat', 'animal'),\n",
       " ('cat', 'dog'),\n",
       " ('dog', 'animal'),\n",
       " ('dog', 'cat'),\n",
       " ('animal', 'dog'),\n",
       " ('animal', 'cat')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skip_grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({('banana', 'fruit'): 1,\n",
       "         ('banana', 'apple'): 1,\n",
       "         ('apple', 'fruit'): 1,\n",
       "         ('apple', 'banana'): 1,\n",
       "         ('fruit', 'apple'): 1,\n",
       "         ('fruit', 'banana'): 1,\n",
       "         ('cat', 'animal'): 1,\n",
       "         ('cat', 'dog'): 1,\n",
       "         ('dog', 'animal'): 1,\n",
       "         ('dog', 'cat'): 1,\n",
       "         ('animal', 'dog'): 1,\n",
       "         ('animal', 'cat'): 1})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#since we have these occurrences, we can count, to make our co-occurrence matrix!!!\n",
    "X_ik_skipgram = Counter(skip_grams)\n",
    "X_ik_skipgram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_ik_skipgram[('banana', 'animal')]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Weighting function f\n",
    "\n",
    "GloVe includes a weighting function to scale down too frequent words.\n",
    "\n",
    "<img src = \"../figures/glove_weighting_func.png\" width=400>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighting(w_i, w_j, X_ik):   #why we need w_i and w_j, because we can try its co-occurrences, if it's too big, we scale it down\n",
    "    \n",
    "    #check whether the co-occurrences between these two word exists???\n",
    "    try:\n",
    "        x_ij = X_ik[(w_i, w_j)]\n",
    "    except:\n",
    "        x_ij = 1  #why one, so that the probability thingy won't break...(label smoothing)\n",
    "        \n",
    "    #maximum co-occurrences; we follow the paper\n",
    "    x_max = 100\n",
    "    alpha = 0.75\n",
    "    \n",
    "    #if the co-occurrences does not exceed x_max, scale it down based on some alpha\n",
    "    if x_ij < x_max:\n",
    "        result = (x_ij/x_max) ** alpha\n",
    "    else:\n",
    "        result = 1 #this is the maximum probability you can have\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03162277660168379\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "w_i  = 'banana'\n",
    "w_j  = 'fruit'\n",
    "w_j2 = 'chaky'\n",
    "\n",
    "print(weighting(w_i, w_j, X_ik_skipgram))   #scales from 1 to 0.0316\n",
    "print(weighting(w_i, w_j2, X_ik_skipgram))  #the paper says that f(0) = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['apple', 'fruit', 'dog', 'banana', 'cat', 'animal', '<UNK>']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now apply this weighting to all possible pairs\n",
    "from itertools import combinations_with_replacement\n",
    "\n",
    "X_ik = {} #for keeping the co-occurrences\n",
    "weighting_dic = {} #for keeping all the probability after passing through the weighting function\n",
    "\n",
    "for bigram in combinations_with_replacement(vocabs, 2):  #we need to also think its reverse\n",
    "    #if this bigram exists in X_ik_skipgrams\n",
    "    #we gonna add this to our co-occurence matrix\n",
    "    if X_ik_skipgram.get(bigram) is not None:\n",
    "        cooc = X_ik_skipgram[bigram]  #get the co-occurrence\n",
    "        X_ik[bigram] = cooc + 1 #this is again basically label smoothing....(stability issues (especially when divide something))\n",
    "        X_ik[(bigram[1], bigram[0])] = cooc + 1  #trick to get all pairs\n",
    "    else: #otherwise, do nothing\n",
    "        pass\n",
    "    \n",
    "    #apply the weighting function using this co-occurrence matrix thingy    \n",
    "    weighting_dic[bigram] = weighting(bigram[0], bigram[1], X_ik)\n",
    "    weighting_dic[(bigram[1], bigram[0])] = weighting(bigram[1], bigram[0], X_ik)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_ik_skipgram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('apple', 'fruit'): 2,\n",
       " ('fruit', 'apple'): 2,\n",
       " ('apple', 'banana'): 2,\n",
       " ('banana', 'apple'): 2,\n",
       " ('fruit', 'banana'): 2,\n",
       " ('banana', 'fruit'): 2,\n",
       " ('dog', 'cat'): 2,\n",
       " ('cat', 'dog'): 2,\n",
       " ('dog', 'animal'): 2,\n",
       " ('animal', 'dog'): 2,\n",
       " ('cat', 'animal'): 2,\n",
       " ('animal', 'cat'): 2}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_ik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weighting_dic  #give small probability to never-occurred is called \"label smoothing\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Prepare train data\n",
    "You move the window along, and create those tuples as we said in class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['apple', 'banana', 'fruit']\n",
      "['banana', 'apple', 'fruit']\n",
      "['banana', 'fruit', 'apple']\n",
      "['dog', 'cat', 'animal']\n",
      "['cat', 'dog', 'animal']\n",
      "['cat', 'animal', 'dog']\n"
     ]
    }
   ],
   "source": [
    "for c in corpus_tokenized:\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('banana', 'fruit'),\n",
       " ('banana', 'apple'),\n",
       " ('apple', 'fruit'),\n",
       " ('apple', 'banana'),\n",
       " ('fruit', 'apple'),\n",
       " ('fruit', 'banana'),\n",
       " ('cat', 'animal'),\n",
       " ('cat', 'dog'),\n",
       " ('dog', 'animal'),\n",
       " ('dog', 'cat'),\n",
       " ('animal', 'dog'),\n",
       " ('animal', 'cat')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skip_grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def random_batch(batch_size, word_sequence, skip_grams, X_ik, weighting_dic):\n",
    "    \n",
    "    #loop through this skipgram, and change it id  because when sending model, it must number\n",
    "    skip_grams_id = [(word2index[skip_gram[0]], word2index[skip_gram[1]]) for skip_gram in skip_grams]\n",
    "    \n",
    "    #randomly pick \"batch_size\" indexes\n",
    "    number_of_choices = len(skip_grams_id)\n",
    "    random_index = np.random.choice(number_of_choices, batch_size, replace=False) #no repeating indexes among these random indexes\n",
    "    \n",
    "    random_inputs = [] #xi, wi (in batches)\n",
    "    random_labels = [] #xj, wj (in batches)\n",
    "    random_coocs  = [] #Xij (in batches)\n",
    "    random_weighting = [] #f(Xij) (in batches)\n",
    "    #for each of the sample in these indexes\n",
    "    for i in random_index:\n",
    "        random_inputs.append([skip_grams_id[i][0]]) #same reason why i put bracket here....\n",
    "        random_labels.append([skip_grams_id[i][1]])\n",
    "        \n",
    "        #get cooc\n",
    "        #first check whether it exists...\n",
    "        pair = skip_grams[i]  #e.g., ('banana', 'fruit)\n",
    "        try:\n",
    "            cooc = X_ik[pair]\n",
    "        except:\n",
    "            cooc = 1 #label smoothing\n",
    "            \n",
    "        random_coocs.append([math.log(cooc)])  #1. why log, #2, why bracket -> size ==> (, 1)  #my neural network expects (, 1)\n",
    "        \n",
    "        #get weighting\n",
    "        weighting = weighting_dic[pair]  #why not use try....maybe it does not exist....\n",
    "        random_weighting.append(weighting)\n",
    "\n",
    "        \n",
    "    return np.array(random_inputs), np.array(random_labels), np.array(random_coocs), np.array(random_weighting)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "input, target, cooc, weightin = random_batch(batch_size, corpus_tokenized, skip_grams, X_ik, weighting_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[2],\n",
       "        [4]]),\n",
       " array([[4],\n",
       "        [5]]),\n",
       " array([[0.69314718],\n",
       "        [0.69314718]]),\n",
       " array([0.05318296, 0.05318296]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input, target, cooc, weightin"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model\n",
    "\n",
    "<img src =\"../figures/glove.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GloVe(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size,embed_size):\n",
    "        super(GloVe,self).__init__()\n",
    "        self.embedding_v = nn.Embedding(vocab_size, embed_size) # center embedding\n",
    "        self.embedding_u = nn.Embedding(vocab_size, embed_size) # out embedding\n",
    "        \n",
    "        self.v_bias = nn.Embedding(vocab_size, 1)\n",
    "        self.u_bias = nn.Embedding(vocab_size, 1)\n",
    "        \n",
    "    def forward(self, center_words, target_words, coocs, weighting):\n",
    "        center_embeds = self.embedding_v(center_words) # [batch_size, 1, emb_size]\n",
    "        target_embeds = self.embedding_u(target_words) # [batch_size, 1, emb_size]\n",
    "        \n",
    "        center_bias = self.v_bias(center_words).squeeze(1)\n",
    "        target_bias = self.u_bias(target_words).squeeze(1)\n",
    "        \n",
    "        inner_product = target_embeds.bmm(center_embeds.transpose(1, 2)).squeeze(2)\n",
    "        #[batch_size, 1, emb_size] @ [batch_size, emb_size, 1] = [batch_size, 1, 1] = [batch_size, 1]\n",
    "        \n",
    "        #note that coocs already got log\n",
    "        loss = weighting*torch.pow(inner_product +center_bias + target_bias - coocs, 2)\n",
    "        \n",
    "        return torch.sum(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc_size   = len(vocabs)\n",
    "batch_size = 2 #why?  no reason; \n",
    "emb_size   = 2 #why?  no reason; usually 50, 100, 300, but 2 so we can plot (50 can also plot, but need PCA)\n",
    "model      = GloVe(voc_size, emb_size)\n",
    "\n",
    "optimizer  = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1000 | Loss: 0.482567 | Time: ??\n",
      "Epoch 2000 | Loss: 0.034147 | Time: ??\n",
      "Epoch 3000 | Loss: 0.304133 | Time: ??\n",
      "Epoch 4000 | Loss: 0.127104 | Time: ??\n",
      "Epoch 5000 | Loss: 0.000083 | Time: ??\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5000\n",
    "#for epoch\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    #get random batch\n",
    "    input, target, cooc, weightin = random_batch(batch_size, corpus_tokenized, skip_grams, X_ik, weighting_dic)\n",
    "    input_batch    = torch.LongTensor(input)\n",
    "    target_batch   = torch.LongTensor(target)\n",
    "    cooc_batch     = torch.FloatTensor(cooc)\n",
    "    weightin_batch = torch.FloatTensor(weightin)\n",
    "    \n",
    "    \n",
    "    # print(input_batch.shape, label_batch.shape, cooc_batch.shape, weightin_batch)\n",
    "    \n",
    "    #loss = model\n",
    "    loss = model(input_batch, target_batch, cooc_batch, weightin_batch)\n",
    "    \n",
    "    #backpropagate\n",
    "    loss.backward()\n",
    "    \n",
    "    #update alpha\n",
    "    optimizer.step()\n",
    "    \n",
    "    #print epoch loss\n",
    "    if (epoch + 1) % 1000 == 0:\n",
    "        print(f\"Epoch {epoch+1} | Loss: {loss:.6f} | Time: ??\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Plot the embeddings\n",
    "\n",
    "Is really the related stuff are close to each other, and vice versa?\n",
    "\n",
    "The most fun part:  Will \"banana\" closer to \"fruit\" than \"cat\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['apple', 'fruit', 'dog', 'banana', 'cat', 'animal', '<UNK>']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "banana = torch.LongTensor([word2index['banana']])\n",
    "banana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.8474, -0.1418]], grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "banana_center_embed = model.embedding_v(banana)\n",
    "banana_outisde_embed = model.embedding_u(banana)\n",
    "\n",
    "banana_embed = (banana_center_embed + banana_outisde_embed) / 2\n",
    "banana_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embed(word):\n",
    "    try:\n",
    "        index = word2index[word]\n",
    "    except:\n",
    "        index = word2index['<UNK>']\n",
    "    \n",
    "    word = torch.LongTensor([index])\n",
    "\n",
    "    center_embed  = model.embedding_v(word)\n",
    "    outside_embed = model.embedding_u(word)\n",
    "    \n",
    "    embed = (center_embed + outside_embed) / 2\n",
    "    \n",
    "    return  embed[0][0].item(), embed[0][1].item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-1.359787106513977, 0.4226120114326477)\n",
      "(-1.9744410514831543, -0.8894343376159668)\n",
      "(0.30555641651153564, -0.6208063960075378)\n"
     ]
    }
   ],
   "source": [
    "#find embedding of fruit, cat\n",
    "print(get_embed('fruit'))\n",
    "print(get_embed('cat'))\n",
    "print(get_embed('chaky'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#help me plot fruit cat banana on matplotlib\n",
    "plt.figure(figsize=(6,3))\n",
    "for i, word in enumerate(vocabs[:20]): #loop each unique vocab\n",
    "    x, y = get_embed(word)\n",
    "    plt.scatter(x, y)\n",
    "    plt.annotate(word, xy=(x, y), xytext=(5, 2), textcoords='offset points')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Cosine similarity\n",
    "\n",
    "How do (from scratch) calculate cosine similarity?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0f2c79af21be9d001248940c049b6176cf8bfb45cabf7aa85848f5cea0f590f6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
